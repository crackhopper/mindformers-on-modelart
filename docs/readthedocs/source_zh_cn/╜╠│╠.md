### Trainer 组件

**<font size=4>Task Trainer 设计</font>**

* Task Trainer 结构

  Task Trainer开发依赖于MindFormers套件中的注册机制，方便开发者使用MindFormers套件提供的各个模块快速完成整网的搭建，各个模块之间可以做到有效的解耦。

![输入图片说明](https://foruda.gitee.com/images/1673431864815390341/da621a72_9324149.png "image-20230103154930330.png")

* Task Trainer 启动

![输入图片说明](https://foruda.gitee.com/images/1673431893333966496/d7bee9e6_9324149.png "image-20230103165657205.png")



**<font size=4>脚本启动</font>**

​	MindFormers套件提供了run_mindformer.py脚本，为MindFormers套件中所有的任务提供了统一的启动接口，其中集成了任务的训练、微调、评估、推理4大流程的快捷启动方式和AICC平台文件交互能力。

- 启动脚本：[run_mindformers.py](https://gitee.com/mindspore/mindformers/blob/r0.3/run_mindformer.py)

- VIT模型使用示例：用户可直接修改对应配置文件`configs`的yaml配置参数，也可直接使用提供的便捷命令完成参数修改，如下：

```shell
# vit 模型训练
python run_mindformer.py \
	--config configs/vit/run_vit_base_p16_100ep.yaml \
	--dataset_dir ~/data/imagenet-1k/train \
	--run_status train \
	--device_id 0

# 自动下载mae预训练权重，微调vit
python run_mindformer.py \
	--config configs/vit/run_vit_base_p16_100ep.yaml \
	--dataset_dir ~/data/imagenet-1k/train \
	--run_status finetune \
	--device_id 0 \
	--load_chenckpoint mae_vit_base_p16  # 支持套件已集成的预训练模型关键词，实现权重自动加载

# profile 性能分析
python run_mindformer.py \
	--config configs/vit/run_vit_base_p16_100ep.yaml \
	--dataset_dir ~/data/imagenet-1k/train \
	--run_status train \
	--device_id 0
	--profile True

# 自动下载已集成的权重进行评估
python run_mindformer.py \
	--config configs/vit/run_vit_base_p16_100ep.yaml \
	--dataset_dir ~/data/imagenet-1k/val \
	--run_status eval \
	--device_id 0

# 自动下载已集成的权重进行推理
python run_mindformer.py \
	--config configs/vit/run_vit_base_p16_100ep.yaml \
	--predict_data ~/predict_images/flower.jpg
	--run_status predict \
	--device_id 0
```

**<font size=4>Trainer 启动</font>**

MindFormers套件为用户在pip安装mindformers之后可以有效的使用已集成的任务进行使用和开发，提供了Trainer易用性的高阶接口。

* Trainer 接口代码：[Trainer](https://gitee.com/mindspore/mindformers/blob/r0.3/mindformers/trainer/trainer.py)
* VIT模型使用示例: 用户可按照MindFormers `docs/model_cards/vit.md`使用教程提前下载好相应数据集[ImageNet1K数据集下载](https://gitee.com/mindspore/mindformers/blob/r0.3/docs/model_cards/vit.md#%E6%95%B0%E6%8D%AE%E9%9B%86%E5%87%86%E5%A4%87)

```python
from mindformers.trainer import Trainer
from mindformers.tools.image_tools import load_image

# 初始化任务
vit_trainer = Trainer(
    task='image_classification',
    model='vit_base_p16',
    train_dataset="imageNet-1k/train",
    eval_dataset="imageNet-1k/val")

vit_trainer.train() # 开启训练
vit_trainer.evaluate() # 开启评估

img = load_image("https://ascend-repo-modelzoo.obs.cn-east-2.myhuaweicloud.com/XFormer_for_mindspore/clip/sunflower.png")
predict_result = vit_trainer.predict(input_data=img, top_k=3) # 开启推理
```

**<font size=4>Task Trainer</font>**

**MindFormers 任务支持情况一览表：**

|                             任务                             | 支持模型                                                     | 支持运行模式（run_mindformer接口） | 支持接口属性（Trainer接口） |
| :----------------------------------------------------------: | ------------------------------------------------------------ | ---------------------------------- | --------------------------- |
|                          fill_mask                           | [bert_base_uncased](https://gitee.com/mindspore/mindformers/blob/r0.3/configs/bert/model_config/bert_base_uncased.yaml) | train                              | train                       |
|                       text_generation                        | [gpt2](https://gitee.com/mindspore/mindformers/blob/r0.3/configs/gpt2/model_config/gpt2.yaml)<br/>[gpt2_13b](https://gitee.com/mindspore/mindformers/blob/r0.3/configs/gpt2/model_config/gpt2_13b.yaml)<br/>[gpt2_52b](https://gitee.com/mindspore/mindformers/blob/r0.3/configs/gpt2/model_config/gpt2_52b.yaml) | train                              | train、predict              |
| [text_classification](https://gitee.com/mindspore/mindformers/blob/r0.3/docs/task_cards/text_classification.md) | [txtcls_bert_base_uncased](https://gitee.com/mindspore/mindformers/blob/r0.3/configs/txtcls/model_config/txtcls_bert_base_uncased.yaml)<br/> [txtcls_bert_base_uncased_mnli](https://gitee.com/mindspore/mindformers/blob/r0.3/configs/txtcls/model_config/txtcls_bert_base_uncased_mnli.yaml) | finetune、eval、predict            | train、evaluate、predict    |
| [token_classification](https://gitee.com/mindspore/mindformers/blob/r0.3/docs/task_cards/token_classification.md) | [tokcls_bert_base_chinese_cluener](https://gitee.com/mindspore/mindformers/blob/r0.3/configs/tokcls/model_config/tokcls_bert_base_chinese_cluener.yaml) | finetune、eval、predict            | train、evaluate、predict    |
| [question_answering](https://gitee.com/mindspore/mindformers/blob/r0.3/docs/task_cards/question_answering.md) | [qa_bert_case_uncased_squad](https://gitee.com/mindspore/mindformers/blob/r0.3/configs/qa/model_config/qa_bert_base_uncased_squad.yaml) | finetune、eval、predict            | train、evaluate、predict    |
|                         translation                          | [t5_small](https://gitee.com/mindspore/mindformers/blob/r0.3/configs/t5/model_config/t5_small.yaml)<br/>[t5_tiny](https://gitee.com/mindspore/mindformers/blob/r0.3/configs/t5/model_config/t5_tiny.yaml) | train、finetune                    | train、predict              |
|                    image_masked_modeling                     | [mae_vit_base_p16](https://gitee.com/mindspore/mindformers/blob/r0.3/configs/mae/model_config/mae_vit_base_p16.yaml) | train                              | train                       |
|                     image_classification                     | [vit_base_p16](https://gitee.com/mindspore/mindformers/blob/r0.3/configs/vit/model_config/vit_base_p16.yaml)<br/>[swin_base_p4w7](https://gitee.com/mindspore/mindformers/blob/r0.3/configs/swin/model_config/swin_base_p4w7.yaml) | train、finetune、eval、predict     | train、evaluate、predict    |
| [contrastive_language_image_pretrain](https://gitee.com/mindspore/mindformers/blob/r0.3/docs/task_cards/contrastive_language_image_pretrain.md) | [clip_vit_b_32](https://gitee.com/mindspore/mindformers/blob/r0.3/configs/clip/model_config/clip_vit_b_32.yaml) <br/> [clip_vit_b_16](https://gitee.com/mindspore/mindformers/blob/r0.3/configs/clip/model_config/clip_vit_b_16.yaml) <br/> [clip_vit_l_14](https://gitee.com/mindspore/mindformers/blob/r0.3/configs/clip/model_config/clip_vit_l_14.yaml) <br/> [clip_vit_l_14@336](https://gitee.com/mindspore/mindformers/blob/r0.3/configs/clip/model_config/clip_vit_l_14@336.yaml) | train                              | train                       |
| [zero_shot_image_classification](https://gitee.com/mindspore/mindformers/blob/r0.3/docs/task_cards/zero_shot_image_classification.md) | [clip_vit_b_32](https://gitee.com/mindspore/mindformers/blob/r0.3/configs/clip/model_config/clip_vit_b_32.yaml) <br/> [clip_vit_b_16](https://gitee.com/mindspore/mindformers/blob/r0.3/configs/clip/model_config/clip_vit_b_16.yaml) <br/> [clip_vit_l_14](https://gitee.com/mindspore/mindformers/blob/r0.3/configs/clip/model_config/clip_vit_l_14.yaml) <br/> [clip_vit_l_14@336](https://gitee.com/mindspore/mindformers/blob/r0.3/configs/clip/model_config/clip_vit_l_14@336.yaml) | eval、predict                      | evaluate、predict           |

#### 完形填空

**任务简介**:

Fill-Mask：俗称“完形填空”，是一种基于掩码语言建模的任务，其中模型需要从句子中的一部分单词中预测被“掩盖”的单词的最可能的词汇。具体而言，BERT输入一组带有掩码的句子，其中每个掩码代表句子中的一个单词被隐藏了。模型需要通过阅读上下文来确定被隐藏的单词最有可能是什么。

**支持模型**：

* [BERT](https://gitee.com/mindspore/mindformers/blob/r0.3/docs/model_cards/bert.md)


脚本使用命令

```shell
# train
python run_mindformer.py --config configs/bert/run_bert_base_uncased.yaml --run_mode train  \
                         --device_target Ascend \
                         --dataset_dir /your_path/wiki_data
```

Trainer接口使用命令

```python
from mindformers.trainer import Trainer

# 初始化预训练任务
trainer = Trainer(task='fill_mask',
    model='bert_base_uncased',
    train_dataset='/your_path/wiki_data')
trainer.train() # 开启预训练
```

#### 文本生成

**任务简介**:

文本生成：生成自然语言文本。模型根据输入的文本和上下文生成类似人类语言的新文本。该任务可以应用于各种应用程序，如聊天机器人、自动摘要、机器翻译、文章生成等。

**支持模型**：

* [GPT2](https://gitee.com/mindspore/mindformers/blob/r0.3/docs/model_cards/gpt2.md)


脚本使用命令

```shell
python run_mindformer.py --config configs/gpt2/run_gpt2.yaml \
                         --run_mode train \
                         --device_target Ascend \
                         --dataset_dir /your_path/wikitext-2-mindrecord
```

Trainer接口使用命令

```python
from mindformers.trainer import Trainer
# 初始化预训练任务
trainer = Trainer(task='text_generation', model='gpt2', train_dataset="your data file path")
# 方式1: 开启训练，并使用训练好的权重进行推理
trainer.train()
res = trainer.predict(predict_checkpoint=True, input_data="I love Beijing, because")

# 方式2： 从obs下载训练好的权重并进行推理
res = trainer.predict(input_data="I love Beijing, because")
```

#### 文本分类

**任务简介**:

文本分类：模型在基于文本对的微调后，可以在给定任意文本对与候选标签列表的情况下，完成对文本对关系的分类，文本对的两个文本之间以-分割。

**支持模型**：

* [BertForMultipleChoice](https://gitee.com/mindspore/mindformers/blob/r0.3/docs/task_cards/text_classification.md)


脚本使用命令

```shell
# finetune
python run_mindformer.py --config ./configs/txtcls/run_txtcls_bert_base_uncased.yaml --run_mode finetune --load_checkpoint txtcls_bert_base_uncased
```

```shell
# evaluate
python run_mindformer.py --config ./configs/txtcls/run_txtcls_bert_base_uncased.yaml --run_mode eval --load_checkpoint txtcls_bert_base_uncased_mnli
```

```shell
# predict
python run_mindformer.py --config ./configs/txtcls/run_txtcls_bert_base_uncased.yaml --run_mode predict --load_checkpoint txtcls_bert_base_uncased_mnli --predict_data [TEXT]
```

Trainer接口使用命令

```python
from mindformers import MindFormerBook
from mindformers.trainer import Trainer

# 显示Trainer的模型支持列表
MindFormerBook.show_trainer_support_model_list("text_classification")
# INFO - Trainer support model list for txt_classification task is:
# INFO -    ['txtcls_bert_base_uncased']
# INFO - -------------------------------------

# 初始化trainer
trainer = Trainer(task='text_classification',
    model='txtcls_bert_base_uncased',
    train_dataset='./mnli/train',
    eval_dataset='./mnli/eval')
# 测试数据，该input_data有两个测试案例，即两个文本对，单个文本对的两个文本之间用-分割
input_data = ["The new rights are nice enough-Everyone really likes the newest benefits ",
              "i don't know um do you do a lot of camping-I know exactly."]

#方式1：使用现有的预训练权重进行finetune， 并使用finetune获得的权重进行eval和推理
trainer.train(resume_or_finetune_from_checkpoint="txtcls_bert_base_uncased",
              do_finetune=True)
trainer.evaluate(eval_checkpoint=True)
trainer.predict(predict_checkpoint=True, input_data=input_data, top_k=1)

# 方式2： 从obs下载训练好的权重并进行eval和推理
trainer.evaluate()
# INFO - Top1 Accuracy=84.8%
trainer.predict(input_data=input_data, top_k=1)
# INFO - output result is [[{'label': 'neutral', 'score': 0.9714198708534241}],
#                         [{'label': 'contradiction', 'score': 0.9967639446258545}]]
```

#### 命名实体识别

**任务简介**:

命名实体识别：模型在基于命名实体识别数据集的微调后，可以在给定任意文本与候选标签列表的情况下，完成对文本中命名实体的识别。

**支持模型**：

* [BertForTokenClassification](https://gitee.com/mindspore/mindformers/blob/r0.3/docs/task_cards/token_classification.md)


脚本使用命令

```shell
# finetune
python run_mindformer.py --config ./configs/tokcls/run_tokcls_bert_base_chinese.yaml --run_mode finetune --load_checkpoint tokcls_bert_base_chinese
```

```shell
# evaluate
python run_mindformer.py --config ./configs/tokcls/run_tokcls_bert_base_chinese.yaml --run_mode eval --load_checkpoint tokcls_bert_base_chinese_cluener
```

```shell
# predict
python run_mindformer.py --config ./configs/tokcls/run_tokcls_bert_base_chinese.yaml --run_mode predict --load_checkpoint tokcls_bert_base_chinese_cluener --predict_data [TEXT]
```

Trainer接口使用命令

```python
from mindformers.trainer import Trainer

# 初始化trainer
trainer = Trainer(task='token_classification',
                  model='tokcls_bert_base_chinese',
                  train_dataset='./cluener/',
                  eval_dataset='./cluener/')
# 测试数据
input_data = ["结果上周六他们主场0：3惨败给了中游球队瓦拉多利德，近7个多月以来西甲首次输球。"]

#方式1：使用现有的预训练权重进行finetune， 并使用finetune获得的权重进行eval和推理
trainer.train(resume_or_finetune_from_checkpoint="tokcls_bert_base_chinese",
              do_finetune=True)
trainer.evaluate(eval_checkpoint=True)
trainer.predict(predict_checkpoint=True, input_data=input_data)

# 方式2： 从obs下载训练好的权重并进行eval和推理
trainer.evaluate()
# INFO - Entity F1=0.7853
trainer.predict(input_data=input_data)
# INFO - output result is [[{'entity_group': 'organization', 'start': 20, 'end': 24, 'score': 0.94914, 'word': '瓦拉多利德'},
#                           {'entity_group': 'organization', 'start': 33, 'end': 34, 'score': 0.9496, 'word': '西甲'}]]
```

#### 问答任务

**任务简介**:

问答任务：模型在基于问答数据集的微调后，输入为上下文（context）和问题（question），模型根据上下文（context）给出相应的回答。

**支持模型**：

* [BertForQuestionAnswering](https://gitee.com/mindspore/mindformers/blob/r0.3/docs/task_cards/question_answering.md)


脚本使用命令

```shell
# finetune
python run_mindformer.py --config ./configs/qa/run_qa_bert_base_uncased.yaml --run_mode finetune --load_checkpoint qa_bert_base_uncased
```

```shell
# evaluate
python run_mindformer.py --config ./configs/qa/run_qa_bert_base_uncased.yaml --run_mode eval --load_checkpoint qa_bert_base_uncased_squad
```

```shell
# predict
python run_mindformer.py --config ./configs/qa/run_qa_bert_base_uncased.yaml --run_mode predict --load_checkpoint qa_bert_base_uncased_squad --predict_data [TEXT]
```

Trainer接口使用命令

```python
  from mindformers.trainer import Trainer
  
  # 初始化trainer
  trainer = Trainer(task='question_answering',
                    model='qa_bert_base_uncased',
                    train_dataset='./squad/',
                    eval_dataset='./squad/')
  
  #方式1：使用现有的预训练权重进行finetune， 并使用finetune获得的权重进行eval和推理
  trainer.train(resume_or_finetune_from_checkpoint="qa_bert_base_uncased",
                do_finetune=True)
  trainer.evaluate(eval_checkpoint=True)
  # 测试数据，测试数据分为context和question两部分，两者以 “-” 分隔
  input_data = ["My name is Wolfgang and I live in Berlin - Where do I live?"]
  trainer.predict(predict_checkpoint=True, input_data=input_data)
  
  # 方式2： 从obs下载训练好的权重并进行eval和推理
  trainer.evaluate()
  # INFO - QA Metric = {'QA Metric': {'exact_match': 80.74739829706716, 'f1': 88.33552874684968}}
  # 测试数据，测试数据分为context和question两部分，两者以 “-” 分隔
  input_data = ["My name is Wolfgang and I live in Berlin - Where do I live?"]
  trainer.predict(input_data=input_data)
  # INFO - output result is [{'text': 'Berlin', 'score': 0.9941, 'start': 34, 'end': 40}]
```

#### 翻译

**任务简介**:

翻译：将一种语言翻译成另一种语言，即进行机器翻译。模型在输入一段文本后，输出对应的翻译结果。例如，将英语句子翻译成法语、汉语、德语等其他语言。

**支持模型**：

* [T5](https://gitee.com/mindspore/mindformers/blob/r0.3/docs/model_cards/t5.md)


脚本使用命令

```shell
python run_mindformer.py --config configs/t5/run_t5_tiny_on_wmt16.yaml --run_mode train  \
                         --device_target Ascend \
                         --dataset_dir /your_path/wmt_en_ro
```

Trainer接口使用命令

```python
from mindformers.trainer import Trainer
# 初始化预训练任务
trainer = Trainer(task='translation', model='t5_small', train_dataset="your data file path")

# 方式1: 开启训练，并使用训练好的权重进行推理
trainer.train()
res = trainer.predict(predict_checkpoint=True, input_data="translate the English to Romanian: a good boy!")
print(res)
#[{'translation_text': ['un băiat bun!']}]

# 方式2： 从obs下载训练好的权重并进行推理
res = trainer.predict(input_data="translate the English to Romanian: a good boy!")
print(res)
#[{'translation_text': ['un băiat bun!']}]
```

#### 图像掩码建模

**任务简介**:

图像掩码建模：通过遮蔽图像中的某些部分来预测被遮蔽的部分。这个任务通常涉及在图像中指定一个区域，并将该区域遮蔽，然后使用遮蔽的图像作为输入，从未遮蔽的图像区域中预测遮蔽的部分。这种任务在计算机视觉中被广泛应用，例如，在图像修复和图像合成中，可以使用遮蔽建模来修复或合成图像中的缺失或不完整部分。

**支持模型**：

* [MAE](https://gitee.com/mindspore/mindformers/blob/r0.3/docs/model_cards/mae.md)


脚本使用命令

```shell
# pretrain
python run_mindformer.py --config ./configs/mae/run_mae_vit_base_p16.yaml --run_mode train
```

Trainer接口使用命令

```python
from mindformers.trainer import Trainer

# 初始化任务
mae_trainer = Trainer(
    task='masked_image_modeling',
    model='mae_vit_base_p16',
    train_dataset="imageNet-1k/train")

mae_trainer.train() # 开启训练
```

#### 图像分类

**任务简介**:

图像分类：将输入的图像识别为属于哪一类别。例如，输入一张狗的图片，模型可以识别出这是一只狗，并将其分类为狗这一类别。这种图像分类任务可用于许多应用，如智能相册、图像搜索、人脸识别、安防监控等。

**支持模型**：

* [VIT](https://gitee.com/mindspore/mindformers/blob/r0.3/docs/model_cards/vit.md)


脚本使用命令

```shell
# pretrain
python run_mindformer.py --config ./configs/vit/run_vit_base_p16_224_100ep.yaml --run_mode train
```

```shell
# evaluate
python run_mindformer.py --config ./configs/vit/run_vit_base_p16_224_100ep.yaml --run_mode eval --dataset_dir [DATASET_PATH]
```

```shell
# predict
python run_mindformer.py --config ./configs/vit/run_vit_base_p16_224_100ep.yaml --run_mode predict --predict_data [PATH_TO_IMAGE]
```

Trainer接口使用命令

```python
from mindformers.trainer import Trainer
from mindformers.tools.image_tools import load_image

# 初始化任务
vit_trainer = Trainer(
    task='image_classification',
    model='vit_base_p16',
    train_dataset="imageNet-1k/train",
    eval_dataset="imageNet-1k/val")
img = load_image("https://ascend-repo-modelzoo.obs.cn-east-2.myhuaweicloud.com/XFormer_for_mindspore/clip/sunflower.png")

# 方式1：使用现有的预训练权重进行finetune， 并使用finetune获得的权重进行eval和推理
vit_trainer.train(resume_or_finetune_from_checkpoint="mae_vit_base_p16", do_finetune=True)
vit_trainer.evaluate(eval_checkpoint=True)
predict_result = vit_trainer.predict(predict_checkpoint=True, input_data=img, top_k=3)
print(predict_result)

# 方式2: 重头开始训练，并使用训练好的权重进行eval和推理
vit_trainer.train()
vit_trainer.evaluate(eval_checkpoint=True)
predict_result = vit_trainer.predict(predict_checkpoint=True, input_data=img, top_k=3)
print(predict_result)

# 方式3： 从obs下载训练好的权重并进行eval和推理
vit_trainer.evaluate()
predict_result = vit_trainer.predict(input_data=img, top_k=3)
print(predict_result)
```

* [Swin](https://gitee.com/mindspore/mindformers/blob/r0.3/docs/model_cards/swin.md)


脚本使用命令

```shell
# pretrain
python run_mindformer.py --config ./configs/swin/run_swin_base_p4w7_224_100ep.yaml --run_mode train --dataset_dir [DATASET_PATH]
```

```shell
# evaluate
python run_mindformer.py --config ./configs/swin/run_swin_base_p4w7_224_100ep.yaml --run_mode eval --dataset_dir [DATASET_PATH]
```

```shell
# predict
python run_mindformer.py --config ./configs/swin/run_swin_base_p4w7_224_100ep.yaml --run_mode predict --predict_data [PATH_TO_IMAGE]
```

Trainer接口使用命令

```python
from mindformers.trainer import Trainer
from mindformers.tools.image_tools import load_image

# 初始化任务
swin_trainer = Trainer(
    task='image_classification',
    model='swin_base_p4w7',
    train_dataset="imageNet-1k/train",
    eval_dataset="imageNet-1k/val")
img = load_image("https://ascend-repo-modelzoo.obs.cn-east-2."
            "myhuaweicloud.com/XFormer_for_mindspore/clip/sunflower.png")

# 方式1：开启训练，并使用训练好的权重进行eval和推理
swin_trainer.train()
swin_trainer.evaluate(eval_checkpoint=True)
predict_result = swin_trainer.predict(predict_checkpoint=True, input_data=img, top_k=3)
print(predict_result)

# 方式2： 从obs下载训练好的权重并进行eval和推理
swin_trainer.evaluate() # 下载权重进行评估
predict_result = swin_trainer.predict(input_data=img, top_k=3) # 下载权重进行推理
print(predict_result)

# 输出
# - mindformers - INFO - output result is: [[{'score': 0.89573187, 'label': 'daisy'},
# {'score': 0.005366202, 'label': 'bee'}, {'score': 0.0013296203, 'label': 'fly'}]]
```

#### 语言图像对比预训练

**任务简介**:

语言图像对比预训练：对模型进行图文对比学习，增强模型对文本图片的匹配度认识能力，预训练完的模型可用于零样本图像分类等下游任务

**支持模型**：

* [CLIP](https://gitee.com/mindspore/mindformers/blob/r0.3/docs/model_cards/clip.md)


Trainer接口使用命令

```python
from mindformers import MindFormerBook
from mindformers.trainer import Trainer

# 显示Trainer的模型支持列表
MindFormerBook.show_trainer_support_model_list("contrastive_language_image_pretrain")
# INFO - Trainer support model list for contrastive_language_image_pretrain task is:
# INFO -    ['clip_vit_b_32', 'clip_vit_b_16', 'clip_vit_l_14', 'clip_vit_l_14@336']
# INFO - -------------------------------------

# 初始化trainer
trainer = Trainer(task='contrastive_language_image_pretrain',
    model='clip_vit_b_32',
    train_dataset='./Flickr8k'
)

trainer.train()
```

#### 零样本图像分类

**任务简介**:

零样本图像分类：模型在基于图文对的预训练后，可以在给定任意图片与候选标签列表的情况下，完成对图像的分类，而无需任何微调。

**支持模型**：

* [CLIP](https://gitee.com/mindspore/mindformers/blob/r0.3/docs/model_cards/clip.md)


Trainer接口使用命令

```python
from mindformers import MindFormerBook
from mindformers.trainer import Trainer
from mindformers.tools.image_tools import load_image

# 显示Trainer的模型支持列表
MindFormerBook.show_trainer_support_model_list("zero_shot_image_classification")
# INFO - Trainer support model list for zero_shot_image_classification task is:
# INFO -    ['clip_vit_b_32', 'clip_vit_b_16', 'clip_vit_l_14', 'clip_vit_l_14@336']
# INFO - -------------------------------------

# 初始化trainer
trainer = Trainer(task='zero_shot_image_classification',
    model='clip_vit_b_32',
    eval_dataset='cifar-100-python'
)
img = load_image("https://ascend-repo-modelzoo.obs.cn-east-2."
          "myhuaweicloud.com/XFormer_for_mindspore/clip/sunflower.png")
trainer.evaluate()  #下载权重进行评估
# INFO - Top1 Accuracy=57.24%
trainer.predict(input_data=img)  #下载权重进行推理
# INFO - output result is saved at ./results.txt
```

### Pipeline 组件

**<font size=4>Task Pipeline 设计</font>**

MindFormers大模型套件面向任务设计pipeline推理接口，旨在让用户可以便捷的体验不同AI领域的大模型在线推理服务。

![输入图片说明](https://foruda.gitee.com/images/1673432339378334189/fb24c2fe_9324149.png "image-20230104093648200.png")

**<font size=4>Task Pipeline</font>**

MindFormers大模型套件为用户提供了pipeline高阶API，支持用户便捷的使用套件中已经集成的任务和模型完成推理流程。

**MindFormers 任务推理支持情况一览表：**

|                             任务                             | 支持模型                                                     | 支持推理数据   |
| :----------------------------------------------------------: | ------------------------------------------------------------ | -------------- |
|                       text_generation                        | [gpt2](https://gitee.com/mindspore/mindformers/blob/r0.3/configs/gpt2/model_config/gpt2.yaml)<br/>[gpt2_13b](https://gitee.com/mindspore/mindformers/blob/r0.3/configs/gpt2/model_config/gpt2_13b.yaml)<br/>[gpt2_52b](https://gitee.com/mindspore/mindformers/blob/r0.3/configs/gpt2/model_config/gpt2_52b.yaml) | 文本数据       |
| [text_classification](https://gitee.com/mindspore/mindformers/blob/r0.3/docs/task_cards/text_classification.md) | [txtcls_bert_base_uncased](https://gitee.com/mindspore/mindformers/blob/r0.3/configs/txtcls/model_config/txtcls_bert_base_uncased.yaml)<br/> [txtcls_bert_base_uncased_mnli](https://gitee.com/mindspore/mindformers/blob/r0.3/configs/txtcls/model_config/txtcls_bert_base_uncased_mnli.yaml) | 文本数据       |
| [token_classification](https://gitee.com/mindspore/mindformers/blob/r0.3/docs/task_cards/token_classification.md) | [tokcls_bert_base_chinese_cluener](https://gitee.com/mindspore/mindformers/blob/r0.3/configs/tokcls/model_config/tokcls_bert_base_chinese_cluener.yaml) | 文本数据       |
| [question_answering](https://gitee.com/mindspore/mindformers/blob/r0.3/docs/task_cards/question_answering.md) | [qa_bert_case_uncased_squad](https://gitee.com/mindspore/mindformers/blob/r0.3/configs/qa/model_config/qa_bert_base_uncased_squad.yaml) | 文本数据       |
|                         translation                          | [t5_small](https://gitee.com/mindspore/mindformers/blob/r0.3/configs/t5/model_config/t5_small.yaml)<br/>[t5_tiny](https://gitee.com/mindspore/mindformers/blob/r0.3/configs/t5/model_config/t5_tiny.yaml) | 文本数据       |
|                     image_classification                     | [vit_base_p16](https://gitee.com/mindspore/mindformers/blob/r0.3/configs/vit/model_config/vit_base_p16.yaml)<br/>[swin_base_p4w7](https://gitee.com/mindspore/mindformers/blob/r0.3/configs/swin/model_config/swin_base_p4w7.yaml) | 图像数据       |
| [zero_shot_image_classification](https://gitee.com/mindspore/mindformers/blob/r0.3/docs/task_cards/zero_shot_image_classification.md) | [clip_vit_b_32](https://gitee.com/mindspore/mindformers/blob/r0.3/configs/clip/model_config/clip_vit_b_32.yaml) <br/> [clip_vit_b_16](https://gitee.com/mindspore/mindformers/blob/r0.3/configs/clip/model_config/clip_vit_b_16.yaml) <br/> [clip_vit_l_14](https://gitee.com/mindspore/mindformers/blob/r0.3/configs/clip/model_config/clip_vit_l_14.yaml) <br/> [clip_vit_l_14@336](https://gitee.com/mindspore/mindformers/blob/r0.3/configs/clip/model_config/clip_vit_l_14@336.yaml) | 图像和文本数据 |

#### 文本生成

**任务简介**:

文本生成：生成自然语言文本。模型根据输入的文本和上下文生成类似人类语言的新文本。该任务可以应用于各种应用程序，如聊天机器人、自动摘要、机器翻译、文章生成等。

**支持模型**：

* [GPT2](https://gitee.com/mindspore/mindformers/blob/r0.3/docs/model_cards/gpt2.md)


**使用样例：**

```python
from mindformers.pipeline import pipeline
pipeline_task = pipeline("text_generation", model='gpt2', max_length=20)
pipeline_result = pipeline_task("I love Beijing, because", top_k=3)
print(pipeline_result)
```

#### 文本分类

**任务简介**:

文本分类：模型在基于文本对的微调后，可以在给定任意文本对与候选标签列表的情况下，完成对文本对关系的分类，文本对的两个文本之间以-分割。

**支持模型**：

* [BertForMultipleChoice](https://gitee.com/mindspore/mindformers/blob/r0.3/docs/task_cards/text_classification.md)

**使用样例：**

```python
from mindformers.pipeline import TextClassificationPipeline
from mindformers import AutoTokenizer, BertForMultipleChoice, AutoConfig

input_data = ["The new rights are nice enough-Everyone really likes the newest benefits ",
                "i don't know um do you do a lot of camping-I know exactly."]

tokenizer = AutoTokenizer.from_pretrained('txtcls_bert_base_uncased_mnli')
txtcls_mnli_config = AutoConfig.from_pretrained('txtcls_bert_base_uncased_mnli')

# Because batch_size parameter is required when bert model is created, and pipeline
# function deals with samples one by one, the batch_size parameter is seted one.
txtcls_mnli_config.batch_size = 1

model = BertForMultipleChoice(txtcls_mnli_config)
txtcls_pipeline = TextClassificationPipeline(task='text_classification',
                                             model=model,
                                             tokenizer=tokenizer,
                                             max_length=model.config.seq_length,
                                             padding="max_length")

results = txtcls_pipeline(input_data, top_k=1)
print(results)
# 输出
# [[{'label': 'neutral', 'score': 0.9714198708534241}], [{'label': 'contradiction', 'score': 0.9967639446258545}]]
```

#### 命名实体识别

**任务简介**:

命名实体识别：模型在基于命名实体识别数据集的微调后，可以在给定任意文本与候选标签列表的情况下，完成对文本中命名实体的识别。

**支持模型**：

* [BertForTokenClassification](https://gitee.com/mindspore/mindformers/blob/r0.3/docs/task_cards/token_classification.md)

**使用样例：**

```python
from mindformers.pipeline import TokenClassificationPipeline
from mindformers import AutoTokenizer, BertForTokenClassification, AutoConfig
from mindformers.dataset.labels import cluener_labels

input_data = ["表身刻有代表日内瓦钟表匠freresoltramare的“fo”字样。"]

id2label = {label_id: label for label_id, label in enumerate(cluener_labels)}

tokenizer = AutoTokenizer.from_pretrained('tokcls_bert_base_chinese_cluener')
tokcls_cluener_config = AutoConfig.from_pretrained('tokcls_bert_base_chinese_cluener')

# This is a known issue, you need to specify batch size equal to 1 when creating bert model.
tokcls_cluener_config.batch_size = 1

model = BertForTokenClassification(tokcls_cluener_config)
tokcls_pipeline = TokenClassificationPipeline(task='token_classification',
                                              model=model,
                                              id2label=id2label,
                                              tokenizer=tokenizer,
                                              max_length=model.config.seq_length,
                                              padding="max_length")

results = tokcls_pipeline(input_data)
print(results)
# 输出
# [[{'entity_group': 'address', 'start': 6, 'end': 8, 'score': 0.52329, 'word': '日内瓦'},
#   {'entity_group': 'name', 'start': 12, 'end': 25, 'score': 0.83922, 'word': 'freresoltramar'}]]
```

#### 问答任务

**任务简介**:

问答任务：模型在基于问答数据集的微调后，输入为上下文（context）和问题（question），模型根据上下文（context）给出相应的回答。

**支持模型**：

* [BertForQuestionAnswering](https://gitee.com/mindspore/mindformers/blob/r0.3/docs/task_cards/question_answering.md)

**使用样例：**

```python
from mindformers.pipeline import QuestionAnsweringPipeline
from mindformers import AutoTokenizer, BertForQuestionAnswering, AutoConfig

# 测试数据，测试数据分为context和question两部分，两者以 “-” 分隔
input_data = ["My name is Wolfgang and I live in Berlin - Where do I live?"]

tokenizer = AutoTokenizer.from_pretrained('qa_bert_base_uncased_squad')
qa_squad_config = AutoConfig.from_pretrained('qa_bert_base_uncased_squad')

# This is a known issue, you need to specify batch size equal to 1 when creating bert model.
qa_squad_config.batch_size = 1

model = BertForQuestionAnswering(qa_squad_config)
qa_pipeline = QuestionAnsweringPipeline(task='question_answering',
                                        model=model,
                                        tokenizer=tokenizer)

results = qa_pipeline(input_data)
print(results)
# 输出
# [{'text': 'Berlin', 'score': 0.9941, 'start': 34, 'end': 40}]
```

#### 翻译

**任务简介**:

翻译：将一种语言翻译成另一种语言，即进行机器翻译。模型在输入一段文本后，输出对应的翻译结果。例如，将英语句子翻译成法语、汉语、德语等其他语言。

**支持模型**：

* [T5](https://gitee.com/mindspore/mindformers/blob/r0.3/docs/model_cards/t5.md)


**使用样例：**

```python
from mindformers.pipeline import pipeline
pipeline_task = pipeline("translation", model='t5_small')
pipeline_result = pipeline_task("translate the English to Romanian: a good boy!", top_k=3)
print(pipeline_result)
#[{'translation_text': ['un băiat bun!']}]
```

#### 图像分类

**任务简介**:

图像分类：将输入的图像识别为属于哪一类别。例如，输入一张狗的图片，模型可以识别出这是一只狗，并将其分类为狗这一类别。这种图像分类任务可用于许多应用，如智能相册、图像搜索、人脸识别、安防监控等。

**支持模型**：

* [VIT](https://gitee.com/mindspore/mindformers/blob/r0.3/docs/model_cards/vit.md)


**使用样例：**

```python
from mindformers.pipeline import pipeline
from mindformers.tools.image_tools import load_image


pipeline_task = pipeline("image_classification", model='vit_base_p16')
img = load_image("https://ascend-repo-modelzoo.obs.cn-east-2.myhuaweicloud.com/XFormer_for_mindspore/clip/sunflower.png")
pipeline_result = pipeline_task(img, top_k=3)
```

* [Swin](https://gitee.com/mindspore/mindformers/blob/r0.3/docs/model_cards/swin.md)


**使用样例：**

```python
from mindformers.pipeline import pipeline
from mindformers.tools.image_tools import load_image


pipeline_task = pipeline("image_classification", model='swin_base_p4w7')
img = load_image("https://ascend-repo-modelzoo.obs.cn-east-2."
          "myhuaweicloud.com/XFormer_for_mindspore/clip/sunflower.png")
pipeline_result = pipeline_task(img, top_k=3)
print(pipeline_result)
# 输出
# [[{'score': 0.89573187, 'label': 'daisy'}, {'score': 0.005366202, 'label': 'bee'},
# {'score': 0.0013296203, 'label': 'fly'}]]
```

#### 零样本图像分类

**任务简介**:

零样本图像分类：模型在基于图文对的预训练后，可以在给定任意图片与候选标签列表的情况下，完成对图像的分类，而无需任何微调。

**支持模型**：

* [CLIP](https://gitee.com/mindspore/mindformers/blob/r0.3/docs/model_cards/clip.md)


**使用样例：**

```python
from mindformers import pipeline
from mindformers.tools.image_tools import load_image

classifier = pipeline("zero_shot_image_classification",
                      model='clip_vit_b_32',
                      candidate_labels=["sunflower", "tree", "dog", "cat", "toy"])
img = load_image("https://ascend-repo-modelzoo.obs.cn-east-2."
                 "myhuaweicloud.com/XFormer_for_mindspore/clip/sunflower.png")
classifier(img)
# result
# [[{'score': 0.99995565, 'label': 'sunflower'},
#  {'score': 2.5318595e-05, 'label': 'toy'},
#  {'score': 9.903885e-06, 'label': 'dog'},
#  {'score': 6.75336e-06, 'label': 'tree'},
#  {'score': 2.396818e-06, 'label': 'cat'}]]
```

### AutoClass 组件

#### AutoClass 设计

MindFormers大模型套件提供了AutoClass类，包含AutoConfig、AutoModel、AutoTokenizer、AutoProcessor4个便捷高阶接口，方便用户调用套件中已封装的API接口，上述4类分别提供了相应领域模型的ModelConfig、Model、Tokenzier、Processor的实例化功能。

![输入图片说明](https://foruda.gitee.com/images/1673434276426093311/70cb1623_9324149.png "image-20230104100951903.png")

#### AutoClass

|  AutoClass类  | from_pretrained属性（实例化功能） | from_config属性（实例化功能） |
| :-----------: | :-------------------------------: | :---------------------------: |
|  AutoConfig   |                 √                 |               ×               |
|   AutoModel   |                 √                 |               √               |
| AutoProcessor |                 √                 |               ×               |
| AutoTokenizer |                 √                 |               ×               |

* AutoClass接口代码：[AutoClass](https://gitee.com/mindspore/mindformers/blob/r0.3/mindformers/auto_class.py)
* AutoConfig 使用样例：利用`from_pretrained`属性完成模型配置的实例化

```python
from mindformers.auto_class import AutoConfig
# 1)  instantiates a config by yaml model name
config_a = AutoConfig.from_pretrained('clip_vit_b_32')

# 2)  instantiates a config by yaml model path
from mindformers.mindformer_book import MindFormerBook
config_path = os.path.join(MindFormerBook.get_project_path(),
                           'configs', 'clip', 'model_config', "clip_vit_b_32.yaml")
config_b = AutoConfig.from_pretrained(config_path)
```

* AutoModel使用样例：利用`from_pretrained`或者`from_config`属性完成网络模型的实例化

```python
from mindformers.auto_class import AutoModel
# 1)  input model name, load model and weights
model_a = AutoModel.from_pretrained('clip_vit_b_32')

# 2)  input model directory, load model and weights
from mindformers.mindformer_book import MindFormerBook
checkpoint_dir = os.path.join(MindFormerBook.get_default_checkpoint_download_folder(), 'clip')
model_b = AutoModel.from_pretrained(checkpoint_dir)

# 3)  input yaml path, load model without weights
config_path = os.path.join(MindFormerBook.get_project_path(),
                           'configs', 'clip', 'model_config', "clip_vit_b_32.yaml")
model_c = AutoModel.from_config(config_path)

# 4)  input config, load model without weights
config = AutoConfig.from_pretrained('clip_vit_b_32')
model_d = AutoModel.from_config(config)
```

* AutoProcessor使用样例：利用`from_pretrained`属性完成数据预处理的实例化

```python
from mindformers.auto_class import AutoProcessor
# 1)  instantiates a processor by yaml model name
pro_a = AutoProcessor.from_pretrained('clip_vit_b_32')

# 2)  instantiates a processor by yaml model path
from mindformers.mindformer_book import MindFormerBook
config_path = os.path.join(MindFormerBook.get_project_path(),
                           'configs', 'clip', 'model_config', "clip_vit_b_32.yaml")
pro_b = AutoProcessor.from_pretrained(config_path)
```

* AutoTokenizer使用样例：利用`from_pretrained`属性完成tokenizer的实例化

```python
from mindformers.auto_class import AutoTokenizer
# 1)  instantiates a tokenizer by the model name
tokenizer_a = AutoTokenizer.from_pretrained("clip_vit_b_32")

# 2)  instantiates a tokenizer by the path to the downloaded files.
from mindformers.models.clip.clip_tokenizer import ClipTokenizer
clip_tokenizer = ClipTokenizer.from_pretrained("clip_vit_b_32")
clip_tokenizer.save_pretrained(path_saved)
restore_tokenizer = AutoTokenizer.from_pretrained(path_saved)
```

### Model 组件

MindFormers套件为用户提供了所有已集成模型的对外API接口，用户可以使用相应的模块来自定义自己的网络模型，下面给出套件已经支持模型：

#### Vision Model

##### MAE

* [ViTMAEConfig](https://gitee.com/mindspore/mindformers/blob/r0.3/mindformers/models/mae/mae_config.py#L27)

* [ViTMAEModell](https://gitee.com/mindspore/mindformers/blob/r0.3/mindformers/models/mae/mae.py#L34)

* [ViTMAEForPreTraining](https://gitee.com/mindspore/mindformers/blob/r0.3/mindformers/models/mae/mae.py#L184)

**使用样例**

```python
from mindformers import ViTMAEConfig, ViTMAEModel, ViTMAEForPreTraining

# 自动实例化默认MAE模型配置
mae_config= ViTMAEConfig.from_pretrained('mae_vit_base_p16')

# 自定义MAE模型配置
mae_config= ViTMAEConfig(mask_ratio=0.75,
                         image_size=224,
                         patch_size=16,
                         hidden_size=768,
                         num_hidden_layers=12)

# 自动实例化MAE网络
mae_model1 = ViTMAEModel.from_pretrained('mae_vit_base_p16')
mae_model2 = ViTMAEForPreTraining.from_pretrained('mae_vit_base_p16')

# 自定义实例化MAE网络
mae_model1 = ViTMAEModel(mae_config)
mae_model2 = ViTMAEForPreTraining(mae_config)
```

##### ViT

* [ViTConfig](https://gitee.com/mindspore/mindformers/blob/r0.3/mindformers/models/vit/vit_config.py#L30)
* [VitModel](https://gitee.com/mindspore/mindformers/blob/r0.3/mindformers/models/vit/vit.py#L34)
* [ViTForImageClassification](https://gitee.com/mindspore/mindformers/blob/r0.3/mindformers/models/vit/vit.py#L193)
* [ViTImageProcessor](https://gitee.com/mindspore/mindformers/blob/r0.3/mindformers/models/vit/vit_processor.py#L32)
* [ViTProcessor](https://gitee.com/mindspore/mindformers/blob/r0.3/mindformers/models/vit/vit_processor.py#L116)

**使用样例**

```python
from mindformers import ViTConfig, ViTModel, ViTForImageClassification, \
    ViTImageProcessor, ViTProcessor

# 自动实例化默认ViT模型配置
vit_config= ViTConfig.from_pretrained('vit_base_p16')

# 自定义ViT模型配置
vit_config= ViTConfig(image_size=224,
                      patch_size=16,
                      hidden_size=768,
                      num_hidden_layers=12)

# 自动实例化ViT网络
vit_model1 = ViTModel.from_pretrained('vit_base_p16')
vit_model2 = ViTForImageClassification.from_pretrained('vit_base_p16')

# 自定义实例化ViT网络
vit_model1 = ViTModel(vit_config)
vit_model2 = ViTForImageClassification(vit_config)

# 自动实例化ViT数据预处理
vit_processor = ViTProcessor.from_pretrained('vit_base_p16')

# 自定义实例化ViT数据预处理
image_processor = ViTImageProcessor(size=224)
vit_processor = ViTProcessor(image_processor)
```

##### Swin

* [SwinConfig](https://gitee.com/mindspore/mindformers/blob/r0.3/mindformers/models/swin/swin_config.py#L33)
* [SwinModel](https://gitee.com/mindspore/mindformers/blob/r0.3/mindformers/models/swin/swin.py#L53)
* [SwinForImageClassification](https://gitee.com/mindspore/mindformers/blob/r0.3/mindformers/models/swin/swin.py#L174)
* [SwinImageProcessor](https://gitee.com/mindspore/mindformers/blob/r0.3/mindformers/models/swin/swin_processor.py#L35)
* [SwinProcessor](https://gitee.com/mindspore/mindformers/blob/r0.3/mindformers/models/swin/swin_processor.py#L118)

**使用样例**

```python
from mindformers import SwinConfig, SwinModel, SwinForImageClassification, \
    SwinImageProcessor, SwinProcessor

# 自动实例化默认Swin模型配置
swin_config= SwinConfig.from_pretrained('swin_base_p4w7')

# 自定义Swin模型配置
swin_config= SwinConfig(image_size=224,
                        patch_size=3,
                        embed_dim=128,
                        depth=(2, 2, 18, 2))

# 自动实例化Swin网络
swin_model1 = SwinModel.from_pretrained('swin_base_p4w7')
swin_model2 = SwinForImageClassification.from_pretrained('swin_base_p4w7')

# 自定义实例化Swin网络
swin_model1 = SwinModel(swin_config)
swin_model2 = SwinForImageClassification(swin_config)

# 自动实例化Swin数据预处理
swin_processor = SwinProcessor.from_pretrained('swin_base_p4w7')

# 自定义实例化Swin数据预处理
image_processor = SwinImageProcessor(size=224)
swin_processor = SwinProcessor(image_processor=image_processor)
```

#### Language Model

##### Bert

* [BertConfig](https://gitee.com/mindspore/mindformers/blob/r0.3/mindformers/models/bert/bert_config.py#L26)

* [BertTokenizer](https://gitee.com/mindspore/mindformers/blob/r0.3/mindformers/models/bert/bert_tokenizer.py#L309)

* [BertProcessor](https://gitee.com/mindspore/mindformers/blob/r0.3/mindformers/models/bert/bert_processor.py#L27)

* [BertModel](https://gitee.com/mindspore/mindformers/blob/r0.3/mindformers/models/bert/bert.py#L199)

* [BertForPreTraining](https://gitee.com/mindspore/mindformers/blob/r0.3/mindformers/models/bert/bert.py#L107)

* [BertTokenClassification](https://gitee.com/mindspore/mindformers/blob/r0.3/mindformers/models/bert/bert.py#L39)

* [BertForMultipleChoice](https://gitee.com/mindspore/mindformers/blob/r0.3/mindformers/models/bert/bert.py#L305)

* [BertForQuestionAnswering](https://gitee.com/mindspore/mindformers/blob/r0.3/mindformers/models/bert/bert.py#L365)

**使用样例**

```python
from mindformers import BertConfig, BertTokenizer, BertProcessor, BertModel, \
    BertForPreTraining, BertTokenClassification, \
    BertForMultipleChoice, BertForQuestionAnswering

# 自动实例化默认Bert模型配置
bert_config= BertConfig.from_pretrained('bert_base_uncased')

# 自定义Bert模型配置
bert_config= BertConfig(seq_length=128,
                        vocab_size=30522,
                        hidden_size=768,
                        num_hidden_layers=12)

# 自动实例化Bert网络
bert_model1 = BertModel.from_pretrained('bert_base_uncased')
bert_model2 = BertForPreTraining.from_pretrained('bert_base_uncased')
bert_model3 = BertTokenClassification.from_pretrained('bert_base_uncased')
bert_model4 = BertForMultipleChoice.from_pretrained('bert_base_uncased')
bert_model5 = BertForQuestionAnswering.from_pretrained('bert_base_uncased')

# 自定义实例化Bert网络
bert_model1 = BertModel(bert_config)
bert_model2 = BertForPreTraining(bert_config)
bert_model3 = BertTokenClassification(bert_config)
bert_model4 = BertForMultipleChoice(bert_config)
bert_model5 = BertForQuestionAnswering(bert_config)

# 自动实例化Bert数据预处理
bert_processor = BertProcessor.from_pretrained('bert_base_uncased')

# 自定义实例化Bert数据预处理
tokenizer = BertTokenizer.from_pretrained('bert_base_uncased')
bert_processor = BertProcessor(tokenizer=tokenizer)
```

##### T5

* [T5Config](https://gitee.com/mindspore/mindformers/blob/r0.3/mindformers/models/t5/t5_config.py#L26)

* [T5Tokenizer](https://gitee.com/mindspore/mindformers/blob/r0.3/mindformers/models/t5/t5_tokenizer.py#L30)

* [T5Processor](https://gitee.com/mindspore/mindformers/blob/r0.3/mindformers/models/t5/t5_processor.py#L27)

* [T5ForConditionalGeneration](https://gitee.com/mindspore/mindformers/blob/r0.3/mindformers/models/t5/t5.py#L1672)

**使用样例**

```python
from mindformers import T5Config, T5Processor, T5Processor, T5ForConditionalGeneration

# 自动实例化默认T5模型配置
t5_config= T5Config.from_pretrained('t5_small')

# 自定义T5模型配置
t5_config= T5Config(vocab_size=32128,
                    d_model=512,
                    d_kv=64,
                    d_ff=2048)

# 自动实例化T5网络
t5_model = T5ForConditionalGeneration.from_pretrained('t5_small')

# 自定义实例化T5网络
t5_model = T5ForConditionalGeneration(t5_config )

# 自动实例化T5数据预处理
t5_processor = T5Processor.from_pretrained('t5_small')

# 自定义实例化T5数据预处理
tokenizer = T5Tokenizer.from_pretrained('t5_small')
t5_processor = T5Processor(tokenizer=tokenizer)
```

##### GPT2

* [GPT2Config](https://gitee.com/mindspore/mindformers/blob/r0.3/mindformers/models/gpt2/gpt2_config.py#L29)

* [GPT2Tokenizer](https://gitee.com/mindspore/mindformers/blob/r0.3/mindformers/models/gpt2/gpt2_tokenizer.py#L60)

* [GPT2Processor](https://gitee.com/mindspore/mindformers/blob/r0.3/mindformers/models/gpt2/gpt2_processor.py#L27)
* [GPT2Model](https://gitee.com/mindspore/mindformers/blob/r0.3/mindformers/models/gpt2/gpt2.py#L188)
* [GPT2LMHeadModel](https://gitee.com/mindspore/mindformers/blob/r0.3/mindformers/models/gpt2/gpt2.py#L40)

**使用样例**

```python
from mindformers import GPT2Config, GPT2Tokenizer, GPT2Processor, GPT2Model, GPT2LMHeadModel

# 自动实例化默认GPT2模型配置
gpt2_config = GPT2Config.from_pretrained('gpt2')

# 自定义GPT2模型配置
gpt2_config = GPT2Config(seq_length=1024,
                         vocab_size=50257,
                         embedding_size=768,
                         num_layers=12)

# 自动实例化GPT2网络
gpt2_model1 = GPT2Model.from_pretrained('clip_vit_b_32')
gpt2_model2 = GPT2LMHeadModel.from_pretrained('clip_vit_b_32')

# 自定义实例化GPT2网络
gpt2_model1 = GPT2Model(gpt2_config )
gpt2_model2 = GPT2LMHeadModel(gpt2_config )

# 自动实例化GPT2数据预处理
gpt2_processor = GPT2Processor.from_pretrained('gpt2')

# 自定义实例化GPT2数据预处理
tokenizer = GPT2Tokenizer.from_pretrained('gpt2')
gpt2_processor = GPT2Processor(tokenizer=tokenizer)
```

#### Multi-Modal

##### CLIP

* [CLIPConfig](https://gitee.com/mindspore/mindformers/blob/r0.3/mindformers/models/clip/clip_config.py#L145)

* [CLIPVisionConfig](https://gitee.com/mindspore/mindformers/blob/r0.3/mindformers/models/clip/clip_config.py#L87)

* [CLIPTextConfig](https://gitee.com/mindspore/mindformers/blob/r0.3/mindformers/models/clip/clip_config.py#L28)

* [CLIPTokenizer](https://gitee.com/mindspore/mindformers/blob/r0.3/mindformers/models/clip/clip_tokenizer.py#L151)

* [CLIPImageProcessor](https://gitee.com/mindspore/mindformers/blob/r0.3/mindformers/models/clip/clip_processor.py#L36)

* [CLIPProcessor](https://gitee.com/mindspore/mindformers/blob/r0.3/mindformers/models/clip/clip_processor.py#L111)

* [CLIPModel](https://gitee.com/mindspore/mindformers/blob/r0.3/mindformers/models/clip/clip.py#L37)

**使用样例**

```python
from mindformers import CLIPConfig, CLIPTextConfig, \
        CLIPVisionConfig, CLIPTokenizer, \
        CLIPProcessor, CLIPModel

# 自动实例化默认CLIP模型配置
clip_config = CLIPConfig.from_pretrained('clip_vit_b_32')

# 自定义CLIP模型配置
clip_config = CLIPConfig(
        CLIPTextConfig(
            hidden_size=512,
            vocab_size=49408,
            max_position_embeddings=77,
            num_hidden_layers=12
        ),
        CLIPVisionConfig(
            hidden_size=768,
            image_size=224,
            patch_size=32,
            num_hidden_layers=12,
        ),
        projection_dim=512
    )

# 自动实例化CLIP网络
clip_model = CLIPModel.from_pretrained('clip_vit_b_32')

# 自定义实例化CLIP网络
clip_model = CLIPModel(clip_config)

# 自动实例化CLIP数据预处理
clip_processor = CLIPProcessor.from_pretrained('clip_vit_b_32')

# 自定义实例化CLIP数据预处理
image_processor = CLIPImageProcessor(image_resolution=224)
tokenizer = CLIPTokenizer.from_pretrained('clip_vit_b_32')

clip_processor = CLIPProcessor(image_processor, tokenizer)
```
